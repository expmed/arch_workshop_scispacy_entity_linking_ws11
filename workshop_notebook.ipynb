{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "S_zvrgde9N9H",
      "metadata": {
        "id": "S_zvrgde9N9H"
      },
      "source": [
        "# Step 1. Loading Public Clinical Notes Data from Hugging Face\n",
        "Per the dataset page on HuggingFace located at [https://huggingface.co/datasets/AGBonnet/augmented-clinical-notes](https://huggingface.co/datasets/AGBonnet/augmented-clinical-notes)\n",
        "\n",
        "### Augmented Clinical Notes\n",
        "\n",
        "The Augmented Clinical Notes dataset is an extension of existing datasets containing 30,000 triplets from different sources:\n",
        "\n",
        "    - Real clinical notes (PMC-Patients): Clinical notes correspond to patient summaries from the PMC-Patients dataset, which are extracted from PubMed Central case studies.\n",
        "    - Synthetic dialogues (NoteChat): Synthetic patient-doctor conversations were generated from clinical notes using GPT 3.5.\n",
        "    - Structured patient information (ours): From clinical notes, we generate structured patient summaries using GPT-4 and a tailored medical information template (see details below).\n",
        "\n",
        "This dataset was used to train MediNote-7B and MediNote-13B, a set of clinical note generators fine-tuned from the MediTron large language models.\n",
        "\n",
        "Our full report is available [here](https://huggingface.co/datasets/AGBonnet/augmented-clinical-notes/blob/main/report.pdf).\n",
        "### Dataset Details\n",
        "\n",
        "    - Curated by: Antoine Bonnet and Paul Boulenger\n",
        "    - Language(s): English only\n",
        "    - Repository: EPFL-IC-Make-Team/ClinicalNotes\n",
        "    - Paper: MediNote: Automated Clinical Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6e2402",
      "metadata": {
        "id": "1e6e2402"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e243e140",
      "metadata": {
        "id": "e243e140"
      },
      "outputs": [],
      "source": [
        "# load in the clinical notes dataset from huggingface\n",
        "df = pd.read_json(\"hf://datasets/AGBonnet/augmented-clinical-notes/augmented_notes_30K.jsonl\", lines=True, nrows=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0791db",
      "metadata": {
        "id": "8b0791db"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TAam8yjq9Vxx",
      "metadata": {
        "id": "TAam8yjq9Vxx"
      },
      "source": [
        "# Step 2. Installation of scispaCy Package and Model for NEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_Uytd5J9jtQ",
      "metadata": {
        "id": "b_Uytd5J9jtQ"
      },
      "outputs": [],
      "source": [
        "!pip install scispacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tJ60zW0j9akV",
      "metadata": {
        "id": "tJ60zW0j9akV"
      },
      "outputs": [],
      "source": [
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VgyfafOY-Ko6",
      "metadata": {
        "id": "VgyfafOY-Ko6"
      },
      "source": [
        "# Step 3. Importing scispaCy package and creation of model for Named Entity Linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LXiKSiZ59fc_",
      "metadata": {
        "id": "LXiKSiZ59fc_"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import scispacy\n",
        "from scispacy.linking import EntityLinker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hrZizxJE-RtR",
      "metadata": {
        "id": "hrZizxJE-RtR"
      },
      "outputs": [],
      "source": [
        "# now we create our model instance which can be used to process biomedical text\n",
        "nlp = spacy.load(\"en_core_sci_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Fq942z1-eSt",
      "metadata": {
        "id": "8Fq942z1-eSt"
      },
      "outputs": [],
      "source": [
        "# now we add a linker to the UMLS knowledgebase to our model pipeline\n",
        "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"mesh\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8CBm8-vCDNxE",
      "metadata": {
        "id": "8CBm8-vCDNxE"
      },
      "outputs": [],
      "source": [
        "linker = nlp.get_pipe(\"scispacy_linker\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822e90de",
      "metadata": {
        "id": "822e90de"
      },
      "source": [
        "### Quick Example: Getting the Entities from one of the Clinical Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed2b863",
      "metadata": {
        "id": "eed2b863"
      },
      "outputs": [],
      "source": [
        "doc = nlp(df['note'][0])\n",
        "for ent in doc.ents[:10]:\n",
        "    print(ent.text, ent.label_, ent._.kb_ents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ko6XqIZsFMIR",
      "metadata": {
        "id": "Ko6XqIZsFMIR"
      },
      "outputs": [],
      "source": [
        "# we can also use displacy to visualize the note and its entities\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SUyBWBBIHBCH",
      "metadata": {
        "id": "SUyBWBBIHBCH"
      },
      "source": [
        "# Step 4. Definition of Function for Extracting Named Entities from the Clinical Notes\n",
        "Here we define a function that, given the text for a note, extracts the top 3 linked vocabulary terms by score/confidence \\\n",
        " for each entity in the note, and then returns these as a pandas `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ChkfTpnCWjG",
      "metadata": {
        "id": "1ChkfTpnCWjG"
      },
      "outputs": [],
      "source": [
        "def get_linked_entities_for_doc(text, nlp, linker):\n",
        "  # get the document\n",
        "  doc = nlp(text)\n",
        "  # get the linked entities\n",
        "  linked_entities = []\n",
        "  for ent in doc.ents: # get all recognized entities\n",
        "    for entry in ent._.kb_ents[:3]: # get the top 3 linked vocabulary terms for each entity\n",
        "      linked_entities.append({\n",
        "          'entity_name': ent.text,\n",
        "          'cui': entry[0],\n",
        "          'score': entry[1],\n",
        "          'linked_entity_name': linker.kb.cui_to_entity[entry[0]].canonical_name,\n",
        "          'linked_entity_definition': linker.kb.cui_to_entity[entry[0]].definition,\n",
        "          'type_ids': ','.join(linker.kb.cui_to_entity[entry[0]].types),\n",
        "      })\n",
        "  return pd.DataFrame(linked_entities).drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d599d12",
      "metadata": {
        "id": "1d599d12"
      },
      "source": [
        "#### Here we get the linked entities for a single document and filter to only include those with a score of at least 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l_TyJxYVDXu3",
      "metadata": {
        "id": "l_TyJxYVDXu3"
      },
      "outputs": [],
      "source": [
        "get_linked_entities_for_doc(df['full_note'][1], nlp, linker).query('score >= 0.9')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kPbNRXDhGhhP",
      "metadata": {
        "id": "kPbNRXDhGhhP"
      },
      "outputs": [],
      "source": [
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jThaBDetDdmI",
      "metadata": {
        "id": "jThaBDetDdmI"
      },
      "outputs": [],
      "source": [
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(df['full_note'][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CUdDPG3rILeb",
      "metadata": {
        "id": "CUdDPG3rILeb"
      },
      "source": [
        "# Step 5. Extracting All Named Entities from The Clinical Notes\n",
        "Now we loop over the clinical notes dataset, and use our previously defined function to \\\n",
        "extract all linked entities for each note with a confidence score >= 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8sNWC-YqIXri",
      "metadata": {
        "id": "8sNWC-YqIXri"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j-M1exzmIQLF",
      "metadata": {
        "id": "j-M1exzmIQLF"
      },
      "outputs": [],
      "source": [
        "linked_entity_dfs = []\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "  linked_entities = get_linked_entities_for_doc(row['full_note'], nlp, linker).query('score >= 0.9')\n",
        "  linked_entity_dfs.append(\n",
        "      linked_entities.assign(type_ids_lst=lambda x: x['type_ids'].str.split(','))\n",
        "      .explode('type_ids_lst').assign(note_id=row['idx'])\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pnl69nWYJM77",
      "metadata": {
        "id": "pnl69nWYJM77"
      },
      "outputs": [],
      "source": [
        "linked_entities_all = pd.concat(linked_entity_dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5HHc7poOKho3",
      "metadata": {
        "id": "5HHc7poOKho3"
      },
      "outputs": [],
      "source": [
        "linked_entities_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8emMpP--K4Ke",
      "metadata": {
        "id": "8emMpP--K4Ke"
      },
      "outputs": [],
      "source": [
        "# inspecting the top 50 occuring linked entity names\n",
        "linked_entities_all['linked_entity_name'].value_counts().head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "REatisA7sKfP",
      "metadata": {
        "id": "REatisA7sKfP"
      },
      "source": [
        "# Step 6. Labeling Semantic Types for All Linked Entities\n",
        "Now we load in a dataset of semantic type labels and link these into the linked entities dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nusdkexPsV13",
      "metadata": {
        "id": "nusdkexPsV13"
      },
      "outputs": [],
      "source": [
        "# first load in the file containing the labels for the semantic types\n",
        "semantic_type_labels = pd.read_csv('https://github.com/expmed/arch_workshop_scispacy_entity_linking_ws11/raw/refs/heads/main/umls_terms.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hbK8rBNBslC3",
      "metadata": {
        "id": "hbK8rBNBslC3"
      },
      "outputs": [],
      "source": [
        "semantic_type_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F9GpwDfjspaO",
      "metadata": {
        "id": "F9GpwDfjspaO"
      },
      "outputs": [],
      "source": [
        "# now we add in these semantic type labels\n",
        "linked_entities_final = linked_entities_all.merge(\n",
        "    semantic_type_labels.rename(columns={'label': 'semantic_type_label'}),\n",
        "    left_on='type_ids_lst',\n",
        "    right_on='tui',\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tCxw5JIKtBf5",
      "metadata": {
        "id": "tCxw5JIKtBf5"
      },
      "outputs": [],
      "source": [
        "linked_entities_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nlWctHbXtUUP",
      "metadata": {
        "id": "nlWctHbXtUUP"
      },
      "source": [
        "## Mini Exercise: Show the Top 20 Most Frequently Occuring Semantic Types Among Linked Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h0kPiA-itdX1",
      "metadata": {
        "id": "h0kPiA-itdX1"
      },
      "outputs": [],
      "source": [
        "# Your solution below...\n",
        "linked_entities_final['semantic_type_label'].value_counts().head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9zFfgUbkKpH0",
      "metadata": {
        "id": "9zFfgUbkKpH0"
      },
      "source": [
        "# Step 7. Utilizing Publicly Available Crosswalk File to Link Entities to MeSH Terms and SNOMED Terms\n",
        "Here we utilize data extracted from the `MRCONSO.RRF` file hosted at [the National Library of Medicine](https://www.nlm.nih.gov/research/umls/new_users/online_learning/Meta_006.html) to crosswalk the CUI #s of the linked entities to Medical Subject Heading (MeSH) terms and Systematized Nomenclature of Medicine (SNOMED) terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aFjQS_GKLBig",
      "metadata": {
        "id": "aFjQS_GKLBig"
      },
      "outputs": [],
      "source": [
        "# first we load in mappings from UMLS concept unique ids to Medical Subject Heading (MeSH) terms\n",
        "mrconso_mesh_mappings = pd.read_parquet('https://github.com/expmed/arch_workshop_scispacy_entity_linking_ws11/raw/refs/heads/main/mrconso_mesh.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uinf_0YYLNbk",
      "metadata": {
        "id": "uinf_0YYLNbk"
      },
      "outputs": [],
      "source": [
        "mrconso_mesh_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPmmv2fgOwjb",
      "metadata": {
        "id": "oPmmv2fgOwjb"
      },
      "outputs": [],
      "source": [
        "# now we can merge the linked entities with the MeSH mappings\n",
        "linked_entities_mesh = linked_entities_final.merge(\n",
        "    mrconso_mesh_mappings,\n",
        "    left_on='cui',\n",
        "    right_on='CUI',\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WSJwryuwO9Uu",
      "metadata": {
        "id": "WSJwryuwO9Uu"
      },
      "outputs": [],
      "source": [
        "linked_entities_mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZBDEwp1OO-N3",
      "metadata": {
        "id": "ZBDEwp1OO-N3"
      },
      "outputs": [],
      "source": [
        "# now we load in the mappings from CUIs to Systematized Nomenclature of Medicine - Clinical Terms\n",
        "mrconso_snomed_mappings = pd.read_parquet('https://github.com/expmed/arch_workshop_scispacy_entity_linking_ws11/raw/refs/heads/main/mrconso_snomed.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed4e82f",
      "metadata": {},
      "outputs": [],
      "source": [
        "mrconso_snomed_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JNuB7665PS7E",
      "metadata": {
        "id": "JNuB7665PS7E"
      },
      "outputs": [],
      "source": [
        "linked_entities_snomed = linked_entities_final.merge(\n",
        "    mrconso_snomed_mappings,\n",
        "    left_on='cui',\n",
        "    right_on='CUI',\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DqU4865DPWNw",
      "metadata": {
        "id": "DqU4865DPWNw"
      },
      "outputs": [],
      "source": [
        "linked_entities_snomed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tZu73eZVPXlr",
      "metadata": {
        "id": "tZu73eZVPXlr"
      },
      "outputs": [],
      "source": [
        "print(f\"{len(linked_entities_snomed.dropna(subset=['CODE'])) / len(linked_entities_snomed) * 100}% of the entities have a SNOMED code\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zk7uZZOXPk4n",
      "metadata": {
        "id": "Zk7uZZOXPk4n"
      },
      "outputs": [],
      "source": [
        "print(f\"{len(linked_entities_mesh.dropna(subset=['CODE'])) / len(linked_entities_mesh) * 100}% of the entities have a MeSH code\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BiYyecvPyG1M",
      "metadata": {
        "id": "BiYyecvPyG1M"
      },
      "source": [
        "# Step 8. Utilize MeSH Hierarchy to Semantically Group Linked Entities\n",
        "This file was originally downloaded from the NIH National Library of Medicine Website at [The Following Link](https://www.nlm.nih.gov/databases/download/mesh.html). The original file is in XML format, which I then processed and converted into a CSV file for ease of loading and reduced disk storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZdonpjTGPv8B",
      "metadata": {
        "id": "ZdonpjTGPv8B"
      },
      "outputs": [],
      "source": [
        "# now load in the MeSH Hierarchy file\n",
        "mesh_hierarchy = pd.read_csv('https://github.com/expmed/arch_workshop_scispacy_entity_linking_ws11/raw/refs/heads/main/mesh_hierarchy.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QjeK4aFA3SGC",
      "metadata": {
        "id": "QjeK4aFA3SGC"
      },
      "outputs": [],
      "source": [
        "mesh_hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HXZcwS3X3TCf",
      "metadata": {
        "id": "HXZcwS3X3TCf"
      },
      "outputs": [],
      "source": [
        "# now we link in the tree numbers to the MeSH mapped entities\n",
        "linked_entities_mesh_hierarchy = linked_entities_mesh.merge(\n",
        "    mesh_hierarchy[['UI', 'tree_number']],\n",
        "    left_on='CODE',\n",
        "    right_on='UI',\n",
        "    how='inner'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D4H0vwGt4gdp",
      "metadata": {
        "id": "D4H0vwGt4gdp"
      },
      "outputs": [],
      "source": [
        "linked_entities_mesh_hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v4VY-aX48G0e",
      "metadata": {
        "id": "v4VY-aX48G0e"
      },
      "outputs": [],
      "source": [
        "# format the mesh hierarchy as a lookup table/dictionary\n",
        "mesh_dictionary = {\n",
        "    row['tree_number']: row['name']\n",
        "    for _, row in tqdm(mesh_hierarchy.iterrows(), total=len(mesh_hierarchy))\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae5b9ae6",
      "metadata": {
        "id": "ae5b9ae6"
      },
      "source": [
        "Here we define a function that iteratively walks down the MeSH hierarchy by taking longer and longer \\\n",
        "prefixes of the MeSH tree numbers, until all tree numbers and their ancestors have been enumerated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tclAG7x64iFb",
      "metadata": {
        "id": "tclAG7x64iFb"
      },
      "outputs": [],
      "source": [
        "# now we specify a function to walk up the MeSH tree for each entity\n",
        "def walk_mesh_hierarchy(entities_df, mesh_hierarchy):\n",
        "  result = entities_df.copy()\n",
        "  # get the set of distinct tree numbers in the dataset\n",
        "  tree_nums = set(entities_df['tree_number'].tolist())\n",
        "  # start at the top level\n",
        "  level = 1\n",
        "  # while we still have tree numbers to process\n",
        "  while len(tree_nums) > 0:\n",
        "    print(f\"Processing level {level}\")\n",
        "    # save the mappings for the current level in a list\n",
        "    level_mappings = []\n",
        "    # keep track of tree numbers to remove after processing this level\n",
        "    to_remove = set()\n",
        "    # loop over the tree nums\n",
        "    for tree_num in tree_nums:\n",
        "      # get the prefix for the current tree level\n",
        "      prefix = '.'.join(tree_num.split(\".\")[:level])\n",
        "      # if the prefix is different from the tree number, save a mapping for the current level\n",
        "      if prefix != tree_num:\n",
        "        level_mappings.append({\n",
        "            'tree_number': tree_num,\n",
        "            f'level_{level}_tree_number': prefix,\n",
        "            f'level_{level}_parent_name': mesh_hierarchy[prefix]\n",
        "        })\n",
        "      else:\n",
        "        # we have already enumerated all ancestors if the prefix matches, so remove the tree number\n",
        "        to_remove.add(tree_num)\n",
        "    # merge in the mappings for the current level if we have any\n",
        "    if len(level_mappings) > 0:\n",
        "      result = result.merge(\n",
        "          pd.DataFrame(level_mappings),\n",
        "          on='tree_number',\n",
        "          how='left'\n",
        "      )\n",
        "    # move one level down the tree\n",
        "    level += 1\n",
        "    # update the set of tree_nums\n",
        "    tree_nums = tree_nums - to_remove\n",
        "  # return the result dataframe\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T-w4YE7k9wSi",
      "metadata": {
        "id": "T-w4YE7k9wSi"
      },
      "outputs": [],
      "source": [
        "linked_entities_mesh_final = walk_mesh_hierarchy(\n",
        "    linked_entities_mesh_hierarchy,\n",
        "    mesh_dictionary\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MaqVnJBx969S",
      "metadata": {
        "id": "MaqVnJBx969S"
      },
      "outputs": [],
      "source": [
        "linked_entities_mesh_final[[\n",
        "    'note_id', 'entity_name', 'linked_entity_name', 'linked_entity_definition', \n",
        "    'semantic_type_label', 'level_1_parent_name', 'level_2_parent_name', 'tree_number'\n",
        "]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ExRlvtWpAPeT",
      "metadata": {
        "id": "ExRlvtWpAPeT"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JKvfbQTNAQX3",
      "metadata": {
        "id": "JKvfbQTNAQX3"
      },
      "outputs": [],
      "source": [
        "# Exercise 1: Count the number of patient notes that mention respiratory tract diseases\n",
        "# HINT: Respiratory tract diseases falls under the column 'level_1_parent_name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O466xnn5Ad0V",
      "metadata": {
        "id": "O466xnn5Ad0V"
      },
      "outputs": [],
      "source": [
        "# Exercise 2: For entities with a tree number prefixed by 'C' (Diseases) Rank them by number of notes mentioning each kind of disease\n",
        "# Use the level 1 parent name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sc6ym6zHBVx9",
      "metadata": {
        "id": "Sc6ym6zHBVx9"
      },
      "outputs": [],
      "source": [
        "# Exercise 3: What are the 10 most frequent anatomical parts mentioned in notes tagged with Neoplasms?\n",
        "# Note: MeSH terms categorized as anatomical have a tree number prefixed by 'A'\n",
        "# use the level 2 parent name\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
